{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uioOSkpBLs9O"
   },
   "source": [
    "# Trabalho BI - Tópicos Avançados - Alocação Latente de Dirichlet (LDA)\n",
    "\n",
    "## Análise de tópicos utilizando a base de serviços das reclamações fundamentadas que foram audiência no ano de 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7137,
     "status": "ok",
     "timestamp": 1595623593083,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "E4ogIMp4Ls9T",
    "outputId": "c9ce529e-ab54-4cda-9822-a9574cc4d5a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation #TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer #, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "#import matplotlib.colors as mcolors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento da base\n",
    "data = pd.read_csv(r'C:\\Users\\rfsantos\\OneDrive - Mongeral Aegon\\2020\\Modulos\\BI\\NLP\\Trabalho\\Arquivos fonte finais\\base reclamacoes Procon.csv', sep = ';', encoding ='windows-1252', keep_default_na = True)"
   ]
  },
  {
   "source": [
    "## Pré-processamento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Consideramos cada linha de serviço como um documento\n",
    "data = [serviço for serviço in data.serviço] \n",
    "print(\"Temos %d documentos.\" %len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenização dos docs\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True remove pontuação\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removendo Stopwords\n",
    "def removeStops(texts, stopwords):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        texts_out.append(\" \".join([token for token in sent if token not in stopwords]))\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords += [\"nao\", \"so\", \"pra\", \"pro\", \"pras\", \"pros\", \"etc\", \"outros\"]\n",
    "data_without_stops = removeStops(data_words, stopwords)\n",
    "\n",
    "# sem stopwords\n",
    "print(data_without_stops[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a matriz Documento-Palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # considerar palavras que ocorreram pelo menos 10 vezes (min_df) \n",
    "                             lowercase=True,                   # converter todas as palavras em minúsculas\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3 - para ser qualificado como token\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_without_stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando GridSearch para encontrar melhor modelo LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de busca\n",
    "search_params = {'n_components': [5, 10, 15], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Inicializa o modelo\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Inicializa Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Faz a Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o \"melhor\" modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Melhor modelo\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Hiperparâmetros do modelo\n",
    "print(\"Melhores parâmetros: \", model.best_params_)\n",
    "\n",
    "# probabilidade logarítmica\n",
    "print(\"Melhor score de probabilidade logarítmica: \", model.best_score_)\n",
    "\n",
    "# Perplexidade\n",
    "print(\"Perplexidade do modelo: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparando os scores de performance dos modelos LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "current_palette = sns.color_palette(\"Set2\", 3)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "sns.lineplot(data=results,\n",
    "             x='param_n_components',\n",
    "             y='mean_test_score',\n",
    "             hue='param_learning_decay',\n",
    "             palette=current_palette,\n",
    "             marker='o'\n",
    "            )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tópico dominante em cada documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics_first10 = df_document_topic[:10].style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics_first10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantidade de Documentos em Cada Tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando o modelo LDA com o pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook() \n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')\n",
    "pyLDAvis.save_html(panel, 'lda.html') \n",
    "pyLDAvis.display(panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 palavras por tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "# data_vectorized\n",
    "topic_words = {}\n",
    "n_top_words = 10\n",
    "\n",
    "for topic, comp in enumerate(best_lda_model.components_):\n",
    "    # for the n-dimensional array \"arr\":\n",
    "    # argsort() returns a ranked n-dimensional array of arr, call it \"ranked_array\"\n",
    "    # which contains the indices that would sort arr in a descending fashion\n",
    "    # for the ith element in ranked_array, ranked_array[i] represents the index of the\n",
    "    # element in arr that should be at the ith index in ranked_array\n",
    "    # ex. arr = [3,7,1,0,3,6]\n",
    "    # np.argsort(arr) -> [3, 2, 0, 4, 5, 1]\n",
    "    # word_idx contains the indices in \"topic\" of the top num_top_words most relevant\n",
    "    # to a given topic ... it is sorted ascending to begin with and then reversed (desc. now)    \n",
    "    word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "\n",
    "    # store the words most relevant to the topic\n",
    "    topic_words[topic] = [vocab[i] for i in word_idx]\n",
    "\n",
    "    \n",
    "for topic, words in topic_words.items():\n",
    "    words = ', '.join(words)\n",
    "    words = str(words)\n",
    "    cloud1 = WordCloud(background_color='black',width=1600, height=800,max_font_size=200,max_words=20,collocations=False).generate(words)\n",
    "\n",
    "    plt.figure(figsize = (20,10))\n",
    "    plt.imshow(cloud1, interpolation='bilinear')\n",
    "    plt.title('Tópico ' + str(topic), fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "cookiesvf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}